{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook computes LRP (Layer-wise Relevance Propagation), SA (Sensitivity Analysis) and GI (GradientxInput) relevances on an exemplary test sentence, and for a chosen relevance *target* class, using a trained bidirectional LSTM, that was trained on the Stanford Sentiment Treebank (SST) dataset.\n",
    "\n",
    "The LRP implementation is based on the following papers:\n",
    "- [https://doi.org/10.1371/journal.pone.0130140](https://doi.org/10.1371/journal.pone.0130140)\n",
    "- [https://doi.org/10.18653/v1/W17-5221](https://doi.org/10.18653/v1/W17-5221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from code.LSTM.LSTM_bidi import * \n",
    "from code.util.heatmap import html_heatmap\n",
    "\n",
    "import codecs\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define input sequence and relevance target class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment classes are encoded the following way:  \n",
    "**0=very negative, 1=negative, 2=neutral, 3=positive, 4=very positive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_sentence(sent_idx):\n",
    "    \"\"\"Returns an SST test set sentence and its true label, sent_idx must be an integer in [1, 2210] total 2210 sentences\"\"\"\n",
    "    idx = 1\n",
    "    with codecs.open(\"./data/sequence_test.txt\", 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line          = line.rstrip('\\n')\n",
    "            line          = line.split('\\t')\n",
    "            true_class    = int(line[0])-1         # true class\n",
    "            words         = line[1].split(' | ')   # sentence as list of words\n",
    "            if idx == sent_idx:#返回 sent_idx 个数的word\n",
    "                return words, true_class\n",
    "            idx +=1\n",
    "\n",
    "def predict(words):\n",
    "    \"\"\"Returns the classifier's predicted class\"\"\"\n",
    "    net                 = LSTM_bidi()                                   # load trained LSTM model..from LSTM_bidi.py\n",
    "    w_indices           = [net.voc.index(w) for w in words] # convert input sentence to word IDs..hz用系统调用号.\n",
    "    printvar(w_indices, True)\n",
    "    net.set_input(w_indices) # set LSTM input sequence..from LSTM_bidi.py\n",
    "    scores              = net.forward() # classification prediction scores.forward(词汇索引):相当于一个五分类的LSTM.\n",
    "    print(\"hz- len(scores):%s scores: %s\" % (len(scores), scores))\n",
    "    printvar(net.get_para(), True)\n",
    "    return np.argmax(scores)  #argmax() return max value index.# 五类情感，选可能性最大的分类      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an input sequence, either select a sentence from the Stanford Sentiment Treebank (SST) test set, or define your own sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hz- varname:default_varname varshape:(8,)  varvalue:['neither', 'funny', 'nor', 'suspenseful', 'nor', 'particularly', 'well-drawn', '.']\n"
     ]
    }
   ],
   "source": [
    "# in \"./data/sequence_test.txt\"\n",
    "#  291 1       neither | funny | nor | suspenseful | nor | particularly | well-drawn | . \n",
    "words, _ = get_test_sentence(291)                                       # SST test set sentence number 291\n",
    "printvar(words, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, uncomment one of the following sentences, or define your own sequence (only words contained in the vocabulary are supported!)\n",
    "#words = ['this','movie','was','actually','neither','that','funny',',','nor','super','witty','.']\n",
    "#words = ['this', 'film', 'does', 'n\\'t', 'care', 'about', 'cleverness', ',', 'wit', 'or', 'any', 'other', 'kind', 'of', 'intelligent', 'humor', '.']\n",
    "#words = ['i','hate','the','movie','though','the','plot','is','interesting','.']\n",
    "#words = ['used', 'to', 'be', 'my', 'favorite']\n",
    "#words = ['not', 'worth', 'the', 'time']\n",
    "#words = ['is', 'n\\'t', 'a', 'bad', 'film'] # Note: misclassified sample!\n",
    "#words = ['is', 'n\\'t', 'very', 'interesting'] \n",
    "#words = ['it', '\\'s', 'easy' ,'to' ,'love' ,'robin' ,'tunney' ,'--' ,'she' ,'\\'s' ,'pretty' ,'and' ,'she' ,'can' ,'act' ,'--' ,'but' ,'it' ,'gets' ,'harder' ,'and' ,'harder' ,'to' ,'understand' ,'her' ,'choices', '.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了理解单个样本的分类/误分类，我们强烈建议使用分类器的预测类作为相关目标类，因为它是模型最有信心的类，因此此设置将更准确地反映分类器在测试样本上的“观点”。（更一般地说，可以选择任何类作为关联目标类。）\n",
    "In order to understand the classification/misclassification of single samples, we highly **recommend using the classifier's *predicted* class as the relevance *target* class**, since it's the class the model is the most confident about, and therefore this setup will reflect the classifier's \"point of view\" on the test sample more accurately.\n",
    "(More generally, it is possible to choose any class as the relevance *target* class.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hz- varname:default_varname varshape:(8,)  varvalue:[7931, 984, 4481, 3890, 4481, 5120, 14520, 32]\n",
      "set_input   self.E.shape: (19538, 60) \n",
      "hz- varname:default_varname varshape:(8, 60)  varvalue:[[ 0.43077913 -0.18169117  0.01742873  0.20541596 -0.03969318  0.10358565\n",
      "   0.05842264  0.15177514 -0.05993763  0.03649869  0.45181909 -0.13671359\n",
      "  -0.5562824  -0.11577738  0.01810146 -0.10536947  0.07183728  0.05874278\n",
      "   0.43677098 -0.16668737  0.01021575  0.05963009 -0.03090432 -0.13102242\n",
      "   0.18614751  0.13063452  0.04894596  0.04302438  0.33930963  0.36994925\n",
      "  -0.01409349  0.01236203 -0.01782743  0.04562677  0.08322706 -0.09145668\n",
      "   0.03557287  0.05164042  0.02314351  0.08243123  0.12775126  0.06966085\n",
      "   0.12123352  0.36728483  0.48453709 -0.1516519   0.03316482 -0.0123687\n",
      "  -0.32789484  0.02922312 -0.29082173  0.09756328  0.16902158 -0.19181284\n",
      "  -0.19844265 -0.19888473  0.05569024  0.18603702 -0.48650596 -0.17591265]\n",
      " [-0.05923684  0.17109026 -0.27417892  0.20940925 -0.09679801 -0.03086549\n",
      "   0.21577458  0.02603678 -0.21074523  0.10994164 -0.14057852 -0.17929302\n",
      "   0.50960153  0.35670811  0.15765785 -0.30953771 -0.02460255  0.00141478\n",
      "  -0.42235729  0.04459151 -0.00066365 -0.12302727  0.05910711  0.36000073\n",
      "  -0.16383901  0.00103003 -0.04537963  0.20432259  0.0838007  -0.29587916\n",
      "  -0.33329341 -0.04485526  0.17247456  0.06051142  0.0607917   0.00739777\n",
      "   0.03604014 -0.04272507 -0.12794654 -0.06654415  0.20372914 -0.0452698\n",
      "  -0.05221559 -0.24980426 -0.16259404  0.36240637 -0.248623   -0.20868196\n",
      "   0.17052744 -0.0639673   0.30236527  0.13860765 -0.21335974 -0.15767188\n",
      "  -0.13449979  0.01312657  0.08489931  0.07782469  0.20839241  0.12423608]\n",
      " [ 0.52126527  0.00431558 -0.04126624 -0.01407296 -0.23717931 -0.03844649\n",
      "  -0.0527091  -0.07186732  0.09429116 -0.06973922  0.23242815 -0.03001141\n",
      "  -0.44699487 -0.17539349 -0.0539404   0.14393932  0.17861585  0.0553614\n",
      "   0.29811871  0.096072   -0.03454963  0.07438853  0.02926035  0.01443055\n",
      "   0.14962842  0.19110715  0.00730035  0.10000744  0.25713116  0.1883207\n",
      "  -0.05685302  0.06127354 -0.16830175  0.05580732 -0.0273376  -0.17194428\n",
      "   0.01185636  0.04293504 -0.02261488  0.1158688  -0.03024387  0.06946306\n",
      "  -0.00137617  0.450966    0.44522622  0.06551315  0.12970531  0.10527938\n",
      "  -0.30793431 -0.04398484 -0.18987116  0.02358238  0.23089474 -0.09777966\n",
      "  -0.07097006 -0.05942883 -0.08740332  0.00752881 -0.515751   -0.05762383]\n",
      " [-0.04210753  0.10662527 -0.14590675  0.15341273  0.13446163  0.13537502\n",
      "   0.06244805  0.02920817 -0.13305242  0.01420681 -0.0741226  -0.23321073\n",
      "   0.1585826   0.13477223  0.16703534 -0.10316048 -0.17088023  0.25320271\n",
      "  -0.1912756   0.14663655 -0.13677938 -0.09933849 -0.07058357  0.12772079\n",
      "  -0.07722453 -0.10585913 -0.12524217  0.10434319 -0.12731291 -0.11189484\n",
      "  -0.1641335   0.05329917  0.24107395  0.04047212  0.25343278  0.14262225\n",
      "   0.1121059  -0.04301693 -0.13084924 -0.22233085  0.18508171 -0.12822407\n",
      "  -0.13899244 -0.10254086 -0.08108122  0.24722444 -0.05801457 -0.03686158\n",
      "   0.1591347   0.03950378  0.18014695  0.05610652 -0.11840763 -0.06781659\n",
      "  -0.23353694  0.04542096 -0.06101601  0.04171649  0.03406196  0.12463706]\n",
      " [ 0.52126527  0.00431558 -0.04126624 -0.01407296 -0.23717931 -0.03844649\n",
      "  -0.0527091  -0.07186732  0.09429116 -0.06973922  0.23242815 -0.03001141\n",
      "  -0.44699487 -0.17539349 -0.0539404   0.14393932  0.17861585  0.0553614\n",
      "   0.29811871  0.096072   -0.03454963  0.07438853  0.02926035  0.01443055\n",
      "   0.14962842  0.19110715  0.00730035  0.10000744  0.25713116  0.1883207\n",
      "  -0.05685302  0.06127354 -0.16830175  0.05580732 -0.0273376  -0.17194428\n",
      "   0.01185636  0.04293504 -0.02261488  0.1158688  -0.03024387  0.06946306\n",
      "  -0.00137617  0.450966    0.44522622  0.06551315  0.12970531  0.10527938\n",
      "  -0.30793431 -0.04398484 -0.18987116  0.02358238  0.23089474 -0.09777966\n",
      "  -0.07097006 -0.05942883 -0.08740332  0.00752881 -0.515751   -0.05762383]\n",
      " [-0.14242433 -0.0089051   0.07817495 -0.15384376 -0.06506146 -0.17795667\n",
      "  -0.23387709 -0.14047004  0.11233536 -0.02264638  0.09093392  0.1597538\n",
      "  -0.08725035 -0.15575956  0.05513778  0.16622713  0.11899965 -0.06804163\n",
      "   0.11093573 -0.09161139  0.17237198  0.0812491   0.05272645 -0.07496778\n",
      "  -0.06211102 -0.16298562  0.16783485 -0.2199254   0.19979918 -0.01546613\n",
      "   0.08020207  0.01794105 -0.21001603 -0.08331943 -0.03110718  0.05122006\n",
      "  -0.22402953 -0.043454   -0.01652628  0.13605917 -0.0685344   0.06316947\n",
      "   0.05430363  0.04682172 -0.00092297 -0.06898506  0.15701498 -0.05505549\n",
      "  -0.16816854 -0.07305533 -0.06262335 -0.0830732   0.09045829  0.00927317\n",
      "   0.2660737  -0.1697754   0.17844182 -0.13580477 -0.01075571 -0.00432271]\n",
      " [ 0.0499203   0.15353441  0.06735977 -0.11949076 -0.07111828 -0.15325449\n",
      "  -0.08373739 -0.07260776 -0.01772292 -0.09584868 -0.01539029  0.12510233\n",
      "  -0.15994231 -0.11459792  0.07665401  0.06220789  0.04962455 -0.12552656\n",
      "   0.02562349 -0.07942298  0.01213293  0.00872709  0.11750251 -0.02055496\n",
      "   0.02988756  0.03029173  0.13568117 -0.01509359  0.14015722  0.0014078\n",
      "   0.1447043  -0.06888426  0.0259378  -0.06971557 -0.09214612  0.06444617\n",
      "  -0.01919829 -0.02839088  0.04149966  0.08505311 -0.04496767  0.00129396\n",
      "   0.05593843  0.03391234 -0.05734287 -0.16296226  0.08982368 -0.02706976\n",
      "   0.0330415   0.0582318   0.03947578 -0.06685234  0.2164683  -0.09727025\n",
      "   0.02684009 -0.1020259   0.04322496 -0.11049104  0.01496133  0.16172718]\n",
      " [-0.03115265 -0.14081979  0.18109424 -0.08109763  0.28308299 -0.17047989\n",
      "  -0.09285047 -0.12880081  0.22656523 -0.36422864  0.03860463  0.14446731\n",
      "   0.12780386 -0.20141611  0.05448997  0.29548383 -0.08744622 -0.05070418\n",
      "  -0.11236221 -0.09047116  0.39596131 -0.07867268  0.1163267  -0.07720935\n",
      "  -0.16353622 -0.09928042  0.17541647 -0.30031437  0.03765502  0.0528492\n",
      "   0.07216424 -0.19277751  0.06861299  0.02021854 -0.12028715 -0.07960646\n",
      "  -0.14801434 -0.1571079  -0.02466626 -0.13008493 -0.22513923  0.07426765\n",
      "   0.13582143 -0.23883568 -0.20463863 -0.24391741  0.08554661  0.06069454\n",
      "   0.16596681  0.07584017 -0.10866436 -0.22689953 -0.12006748  0.07048797\n",
      "   0.18578663 -0.06135613  0.25734591 -0.0589441   0.04836493  0.06590261]]\n",
      "hz- len(scores):5 scores: [ 2.73149687  2.7249559   0.80547211 -1.5359282  -4.6083298 ]\n",
      "hz- varname:default_varname varshape:(3,)  varvalue:(8, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "predicted_class = predict(words) # get predicted class..from run_example.ipynb\n",
    "target_class    = predicted_class  # define relevance target class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neither', 'funny', 'nor', 'suspenseful', 'nor', 'particularly', 'well-drawn', '.']\n",
      "\n",
      "predicted class:           0\n"
     ]
    }
   ],
   "source": [
    "print (words)\n",
    "print (\"\\npredicted class:          \",   predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute LRP relevances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_input   self.E.shape: (19538, 60) \n",
      "hz- varname:default_varname varshape:(8, 60)  varvalue:[[ 0.43077913 -0.18169117  0.01742873  0.20541596 -0.03969318  0.10358565\n",
      "   0.05842264  0.15177514 -0.05993763  0.03649869  0.45181909 -0.13671359\n",
      "  -0.5562824  -0.11577738  0.01810146 -0.10536947  0.07183728  0.05874278\n",
      "   0.43677098 -0.16668737  0.01021575  0.05963009 -0.03090432 -0.13102242\n",
      "   0.18614751  0.13063452  0.04894596  0.04302438  0.33930963  0.36994925\n",
      "  -0.01409349  0.01236203 -0.01782743  0.04562677  0.08322706 -0.09145668\n",
      "   0.03557287  0.05164042  0.02314351  0.08243123  0.12775126  0.06966085\n",
      "   0.12123352  0.36728483  0.48453709 -0.1516519   0.03316482 -0.0123687\n",
      "  -0.32789484  0.02922312 -0.29082173  0.09756328  0.16902158 -0.19181284\n",
      "  -0.19844265 -0.19888473  0.05569024  0.18603702 -0.48650596 -0.17591265]\n",
      " [-0.05923684  0.17109026 -0.27417892  0.20940925 -0.09679801 -0.03086549\n",
      "   0.21577458  0.02603678 -0.21074523  0.10994164 -0.14057852 -0.17929302\n",
      "   0.50960153  0.35670811  0.15765785 -0.30953771 -0.02460255  0.00141478\n",
      "  -0.42235729  0.04459151 -0.00066365 -0.12302727  0.05910711  0.36000073\n",
      "  -0.16383901  0.00103003 -0.04537963  0.20432259  0.0838007  -0.29587916\n",
      "  -0.33329341 -0.04485526  0.17247456  0.06051142  0.0607917   0.00739777\n",
      "   0.03604014 -0.04272507 -0.12794654 -0.06654415  0.20372914 -0.0452698\n",
      "  -0.05221559 -0.24980426 -0.16259404  0.36240637 -0.248623   -0.20868196\n",
      "   0.17052744 -0.0639673   0.30236527  0.13860765 -0.21335974 -0.15767188\n",
      "  -0.13449979  0.01312657  0.08489931  0.07782469  0.20839241  0.12423608]\n",
      " [ 0.52126527  0.00431558 -0.04126624 -0.01407296 -0.23717931 -0.03844649\n",
      "  -0.0527091  -0.07186732  0.09429116 -0.06973922  0.23242815 -0.03001141\n",
      "  -0.44699487 -0.17539349 -0.0539404   0.14393932  0.17861585  0.0553614\n",
      "   0.29811871  0.096072   -0.03454963  0.07438853  0.02926035  0.01443055\n",
      "   0.14962842  0.19110715  0.00730035  0.10000744  0.25713116  0.1883207\n",
      "  -0.05685302  0.06127354 -0.16830175  0.05580732 -0.0273376  -0.17194428\n",
      "   0.01185636  0.04293504 -0.02261488  0.1158688  -0.03024387  0.06946306\n",
      "  -0.00137617  0.450966    0.44522622  0.06551315  0.12970531  0.10527938\n",
      "  -0.30793431 -0.04398484 -0.18987116  0.02358238  0.23089474 -0.09777966\n",
      "  -0.07097006 -0.05942883 -0.08740332  0.00752881 -0.515751   -0.05762383]\n",
      " [-0.04210753  0.10662527 -0.14590675  0.15341273  0.13446163  0.13537502\n",
      "   0.06244805  0.02920817 -0.13305242  0.01420681 -0.0741226  -0.23321073\n",
      "   0.1585826   0.13477223  0.16703534 -0.10316048 -0.17088023  0.25320271\n",
      "  -0.1912756   0.14663655 -0.13677938 -0.09933849 -0.07058357  0.12772079\n",
      "  -0.07722453 -0.10585913 -0.12524217  0.10434319 -0.12731291 -0.11189484\n",
      "  -0.1641335   0.05329917  0.24107395  0.04047212  0.25343278  0.14262225\n",
      "   0.1121059  -0.04301693 -0.13084924 -0.22233085  0.18508171 -0.12822407\n",
      "  -0.13899244 -0.10254086 -0.08108122  0.24722444 -0.05801457 -0.03686158\n",
      "   0.1591347   0.03950378  0.18014695  0.05610652 -0.11840763 -0.06781659\n",
      "  -0.23353694  0.04542096 -0.06101601  0.04171649  0.03406196  0.12463706]\n",
      " [ 0.52126527  0.00431558 -0.04126624 -0.01407296 -0.23717931 -0.03844649\n",
      "  -0.0527091  -0.07186732  0.09429116 -0.06973922  0.23242815 -0.03001141\n",
      "  -0.44699487 -0.17539349 -0.0539404   0.14393932  0.17861585  0.0553614\n",
      "   0.29811871  0.096072   -0.03454963  0.07438853  0.02926035  0.01443055\n",
      "   0.14962842  0.19110715  0.00730035  0.10000744  0.25713116  0.1883207\n",
      "  -0.05685302  0.06127354 -0.16830175  0.05580732 -0.0273376  -0.17194428\n",
      "   0.01185636  0.04293504 -0.02261488  0.1158688  -0.03024387  0.06946306\n",
      "  -0.00137617  0.450966    0.44522622  0.06551315  0.12970531  0.10527938\n",
      "  -0.30793431 -0.04398484 -0.18987116  0.02358238  0.23089474 -0.09777966\n",
      "  -0.07097006 -0.05942883 -0.08740332  0.00752881 -0.515751   -0.05762383]\n",
      " [-0.14242433 -0.0089051   0.07817495 -0.15384376 -0.06506146 -0.17795667\n",
      "  -0.23387709 -0.14047004  0.11233536 -0.02264638  0.09093392  0.1597538\n",
      "  -0.08725035 -0.15575956  0.05513778  0.16622713  0.11899965 -0.06804163\n",
      "   0.11093573 -0.09161139  0.17237198  0.0812491   0.05272645 -0.07496778\n",
      "  -0.06211102 -0.16298562  0.16783485 -0.2199254   0.19979918 -0.01546613\n",
      "   0.08020207  0.01794105 -0.21001603 -0.08331943 -0.03110718  0.05122006\n",
      "  -0.22402953 -0.043454   -0.01652628  0.13605917 -0.0685344   0.06316947\n",
      "   0.05430363  0.04682172 -0.00092297 -0.06898506  0.15701498 -0.05505549\n",
      "  -0.16816854 -0.07305533 -0.06262335 -0.0830732   0.09045829  0.00927317\n",
      "   0.2660737  -0.1697754   0.17844182 -0.13580477 -0.01075571 -0.00432271]\n",
      " [ 0.0499203   0.15353441  0.06735977 -0.11949076 -0.07111828 -0.15325449\n",
      "  -0.08373739 -0.07260776 -0.01772292 -0.09584868 -0.01539029  0.12510233\n",
      "  -0.15994231 -0.11459792  0.07665401  0.06220789  0.04962455 -0.12552656\n",
      "   0.02562349 -0.07942298  0.01213293  0.00872709  0.11750251 -0.02055496\n",
      "   0.02988756  0.03029173  0.13568117 -0.01509359  0.14015722  0.0014078\n",
      "   0.1447043  -0.06888426  0.0259378  -0.06971557 -0.09214612  0.06444617\n",
      "  -0.01919829 -0.02839088  0.04149966  0.08505311 -0.04496767  0.00129396\n",
      "   0.05593843  0.03391234 -0.05734287 -0.16296226  0.08982368 -0.02706976\n",
      "   0.0330415   0.0582318   0.03947578 -0.06685234  0.2164683  -0.09727025\n",
      "   0.02684009 -0.1020259   0.04322496 -0.11049104  0.01496133  0.16172718]\n",
      " [-0.03115265 -0.14081979  0.18109424 -0.08109763  0.28308299 -0.17047989\n",
      "  -0.09285047 -0.12880081  0.22656523 -0.36422864  0.03860463  0.14446731\n",
      "   0.12780386 -0.20141611  0.05448997  0.29548383 -0.08744622 -0.05070418\n",
      "  -0.11236221 -0.09047116  0.39596131 -0.07867268  0.1163267  -0.07720935\n",
      "  -0.16353622 -0.09928042  0.17541647 -0.30031437  0.03765502  0.0528492\n",
      "   0.07216424 -0.19277751  0.06861299  0.02021854 -0.12028715 -0.07960646\n",
      "  -0.14801434 -0.1571079  -0.02466626 -0.13008493 -0.22513923  0.07426765\n",
      "   0.13582143 -0.23883568 -0.20463863 -0.24391741  0.08554661  0.06069454\n",
      "   0.16596681  0.07584017 -0.10866436 -0.22689953 -0.12006748  0.07048797\n",
      "   0.18578663 -0.06135613  0.25734591 -0.0589441   0.04836493  0.06590261]]\n"
     ]
    }
   ],
   "source": [
    "# LRP hyperparameters:\n",
    "eps                 = 0.001                                             # small positive number\n",
    "bias_factor         = 0.0                                               # recommended value\n",
    " \n",
    "net                 = LSTM_bidi()                                       # load trained LSTM model\n",
    "\n",
    "#convert input sentence to word IDs..words=['neither','funny','nor','suspenseful','nor','particularly','well-drawn','.']\n",
    "w_indices           = [net.voc.index(w) for w in words]\n",
    "Rx, Rx_rev, R_rest  = net.lrp(w_indices, target_class, eps, bias_factor)# perform LRP\n",
    "R_words             = np.sum(Rx + Rx_rev, axis=1)  #R表示相关性 compute word-level LRP relevances\n",
    "scores              = net.s.copy()                                      # classification prediction scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction scores:         [ 2.73149687  2.7249559   0.80547211 -1.5359282  -4.6083298 ]\n",
      "\n",
      "LRP target class:          0\n",
      "\n",
      "LRP relevances:\n",
      "\t\t\t    1.86\tneither\n",
      "\t\t\t   -1.58\tfunny\n",
      "\t\t\t    1.50\tnor\n",
      "\t\t\t   -1.54\tsuspenseful\n",
      "\t\t\t    2.00\tnor\n",
      "\t\t\t   -0.04\tparticularly\n",
      "\t\t\t   -0.06\twell-drawn\n",
      "\t\t\t   -0.12\t.\n",
      "\n",
      "LRP heatmap below:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#ff1111\">neither</span> <span style=\"background-color:#3434ff\">funny</span> <span style=\"background-color:#ff4040\">nor</span> <span style=\"background-color:#3a3aff\">suspenseful</span> <span style=\"background-color:#ff0000\">nor</span> <span style=\"background-color:#fafaff\">particularly</span> <span style=\"background-color:#f8f8ff\">well-drawn</span> <span style=\"background-color:#f0f0ff\">.</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (\"prediction scores:        \",   scores)\n",
    "print (\"\\nLRP target class:         \", target_class)\n",
    "print (\"\\nLRP relevances:\")\n",
    "for idx, w in enumerate(words):\n",
    "    print (\"\\t\\t\\t\" + \"{:8.2f}\".format(R_words[idx]) + \"\\t\" + w)\n",
    "print (\"\\nLRP heatmap below:\")    \n",
    "display(HTML(html_heatmap(words, R_words)))#from IPython.display import display, HTML\n",
    "# html_heatmap() from heatmap.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_input   self.E.shape: (19538, 60) \n",
      "hz- varname:default_varname varshape:(8, 60)  varvalue:[[ 0.43077913 -0.18169117  0.01742873  0.20541596 -0.03969318  0.10358565\n",
      "   0.05842264  0.15177514 -0.05993763  0.03649869  0.45181909 -0.13671359\n",
      "  -0.5562824  -0.11577738  0.01810146 -0.10536947  0.07183728  0.05874278\n",
      "   0.43677098 -0.16668737  0.01021575  0.05963009 -0.03090432 -0.13102242\n",
      "   0.18614751  0.13063452  0.04894596  0.04302438  0.33930963  0.36994925\n",
      "  -0.01409349  0.01236203 -0.01782743  0.04562677  0.08322706 -0.09145668\n",
      "   0.03557287  0.05164042  0.02314351  0.08243123  0.12775126  0.06966085\n",
      "   0.12123352  0.36728483  0.48453709 -0.1516519   0.03316482 -0.0123687\n",
      "  -0.32789484  0.02922312 -0.29082173  0.09756328  0.16902158 -0.19181284\n",
      "  -0.19844265 -0.19888473  0.05569024  0.18603702 -0.48650596 -0.17591265]\n",
      " [-0.05923684  0.17109026 -0.27417892  0.20940925 -0.09679801 -0.03086549\n",
      "   0.21577458  0.02603678 -0.21074523  0.10994164 -0.14057852 -0.17929302\n",
      "   0.50960153  0.35670811  0.15765785 -0.30953771 -0.02460255  0.00141478\n",
      "  -0.42235729  0.04459151 -0.00066365 -0.12302727  0.05910711  0.36000073\n",
      "  -0.16383901  0.00103003 -0.04537963  0.20432259  0.0838007  -0.29587916\n",
      "  -0.33329341 -0.04485526  0.17247456  0.06051142  0.0607917   0.00739777\n",
      "   0.03604014 -0.04272507 -0.12794654 -0.06654415  0.20372914 -0.0452698\n",
      "  -0.05221559 -0.24980426 -0.16259404  0.36240637 -0.248623   -0.20868196\n",
      "   0.17052744 -0.0639673   0.30236527  0.13860765 -0.21335974 -0.15767188\n",
      "  -0.13449979  0.01312657  0.08489931  0.07782469  0.20839241  0.12423608]\n",
      " [ 0.52126527  0.00431558 -0.04126624 -0.01407296 -0.23717931 -0.03844649\n",
      "  -0.0527091  -0.07186732  0.09429116 -0.06973922  0.23242815 -0.03001141\n",
      "  -0.44699487 -0.17539349 -0.0539404   0.14393932  0.17861585  0.0553614\n",
      "   0.29811871  0.096072   -0.03454963  0.07438853  0.02926035  0.01443055\n",
      "   0.14962842  0.19110715  0.00730035  0.10000744  0.25713116  0.1883207\n",
      "  -0.05685302  0.06127354 -0.16830175  0.05580732 -0.0273376  -0.17194428\n",
      "   0.01185636  0.04293504 -0.02261488  0.1158688  -0.03024387  0.06946306\n",
      "  -0.00137617  0.450966    0.44522622  0.06551315  0.12970531  0.10527938\n",
      "  -0.30793431 -0.04398484 -0.18987116  0.02358238  0.23089474 -0.09777966\n",
      "  -0.07097006 -0.05942883 -0.08740332  0.00752881 -0.515751   -0.05762383]\n",
      " [-0.04210753  0.10662527 -0.14590675  0.15341273  0.13446163  0.13537502\n",
      "   0.06244805  0.02920817 -0.13305242  0.01420681 -0.0741226  -0.23321073\n",
      "   0.1585826   0.13477223  0.16703534 -0.10316048 -0.17088023  0.25320271\n",
      "  -0.1912756   0.14663655 -0.13677938 -0.09933849 -0.07058357  0.12772079\n",
      "  -0.07722453 -0.10585913 -0.12524217  0.10434319 -0.12731291 -0.11189484\n",
      "  -0.1641335   0.05329917  0.24107395  0.04047212  0.25343278  0.14262225\n",
      "   0.1121059  -0.04301693 -0.13084924 -0.22233085  0.18508171 -0.12822407\n",
      "  -0.13899244 -0.10254086 -0.08108122  0.24722444 -0.05801457 -0.03686158\n",
      "   0.1591347   0.03950378  0.18014695  0.05610652 -0.11840763 -0.06781659\n",
      "  -0.23353694  0.04542096 -0.06101601  0.04171649  0.03406196  0.12463706]\n",
      " [ 0.52126527  0.00431558 -0.04126624 -0.01407296 -0.23717931 -0.03844649\n",
      "  -0.0527091  -0.07186732  0.09429116 -0.06973922  0.23242815 -0.03001141\n",
      "  -0.44699487 -0.17539349 -0.0539404   0.14393932  0.17861585  0.0553614\n",
      "   0.29811871  0.096072   -0.03454963  0.07438853  0.02926035  0.01443055\n",
      "   0.14962842  0.19110715  0.00730035  0.10000744  0.25713116  0.1883207\n",
      "  -0.05685302  0.06127354 -0.16830175  0.05580732 -0.0273376  -0.17194428\n",
      "   0.01185636  0.04293504 -0.02261488  0.1158688  -0.03024387  0.06946306\n",
      "  -0.00137617  0.450966    0.44522622  0.06551315  0.12970531  0.10527938\n",
      "  -0.30793431 -0.04398484 -0.18987116  0.02358238  0.23089474 -0.09777966\n",
      "  -0.07097006 -0.05942883 -0.08740332  0.00752881 -0.515751   -0.05762383]\n",
      " [-0.14242433 -0.0089051   0.07817495 -0.15384376 -0.06506146 -0.17795667\n",
      "  -0.23387709 -0.14047004  0.11233536 -0.02264638  0.09093392  0.1597538\n",
      "  -0.08725035 -0.15575956  0.05513778  0.16622713  0.11899965 -0.06804163\n",
      "   0.11093573 -0.09161139  0.17237198  0.0812491   0.05272645 -0.07496778\n",
      "  -0.06211102 -0.16298562  0.16783485 -0.2199254   0.19979918 -0.01546613\n",
      "   0.08020207  0.01794105 -0.21001603 -0.08331943 -0.03110718  0.05122006\n",
      "  -0.22402953 -0.043454   -0.01652628  0.13605917 -0.0685344   0.06316947\n",
      "   0.05430363  0.04682172 -0.00092297 -0.06898506  0.15701498 -0.05505549\n",
      "  -0.16816854 -0.07305533 -0.06262335 -0.0830732   0.09045829  0.00927317\n",
      "   0.2660737  -0.1697754   0.17844182 -0.13580477 -0.01075571 -0.00432271]\n",
      " [ 0.0499203   0.15353441  0.06735977 -0.11949076 -0.07111828 -0.15325449\n",
      "  -0.08373739 -0.07260776 -0.01772292 -0.09584868 -0.01539029  0.12510233\n",
      "  -0.15994231 -0.11459792  0.07665401  0.06220789  0.04962455 -0.12552656\n",
      "   0.02562349 -0.07942298  0.01213293  0.00872709  0.11750251 -0.02055496\n",
      "   0.02988756  0.03029173  0.13568117 -0.01509359  0.14015722  0.0014078\n",
      "   0.1447043  -0.06888426  0.0259378  -0.06971557 -0.09214612  0.06444617\n",
      "  -0.01919829 -0.02839088  0.04149966  0.08505311 -0.04496767  0.00129396\n",
      "   0.05593843  0.03391234 -0.05734287 -0.16296226  0.08982368 -0.02706976\n",
      "   0.0330415   0.0582318   0.03947578 -0.06685234  0.2164683  -0.09727025\n",
      "   0.02684009 -0.1020259   0.04322496 -0.11049104  0.01496133  0.16172718]\n",
      " [-0.03115265 -0.14081979  0.18109424 -0.08109763  0.28308299 -0.17047989\n",
      "  -0.09285047 -0.12880081  0.22656523 -0.36422864  0.03860463  0.14446731\n",
      "   0.12780386 -0.20141611  0.05448997  0.29548383 -0.08744622 -0.05070418\n",
      "  -0.11236221 -0.09047116  0.39596131 -0.07867268  0.1163267  -0.07720935\n",
      "  -0.16353622 -0.09928042  0.17541647 -0.30031437  0.03765502  0.0528492\n",
      "   0.07216424 -0.19277751  0.06861299  0.02021854 -0.12028715 -0.07960646\n",
      "  -0.14801434 -0.1571079  -0.02466626 -0.13008493 -0.22513923  0.07426765\n",
      "   0.13582143 -0.23883568 -0.20463863 -0.24391741  0.08554661  0.06069454\n",
      "   0.16596681  0.07584017 -0.10866436 -0.22689953 -0.12006748  0.07048797\n",
      "   0.18578663 -0.06135613  0.25734591 -0.0589441   0.04836493  0.06590261]]\n",
      "2.7314968677959888\n",
      "Sanity check passed?  True\n"
     ]
    }
   ],
   "source": [
    "# How to sanity check global relevance conservation:\n",
    "bias_factor        = 1.0                                             # value to use for sanity check\n",
    "Rx, Rx_rev, R_rest = net.lrp(w_indices, target_class, eps, bias_factor)\n",
    "R_tot              = Rx.sum() + Rx_rev.sum() + R_rest.sum()#total:全部的 # sum of all \"input\" relevances\n",
    "\n",
    "printvar(Rx,False)\n",
    "printvar(Rx_rev, False)\n",
    "printvar(R_rest, False)\n",
    "print(R_tot)\n",
    "print(\"Sanity check passed? \", np.allclose(R_tot, net.s[target_class]))\n",
    "#np.allclos():比较两个array是不是每一元素都相等，默认在1e-05的误差范围内"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute SA/GI relevances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_input   self.E.shape: (19538, 60) \n",
      "hz- varname:default_varname varshape:(8, 60)  varvalue:[[ 0.43077913 -0.18169117  0.01742873  0.20541596 -0.03969318  0.10358565\n",
      "   0.05842264  0.15177514 -0.05993763  0.03649869  0.45181909 -0.13671359\n",
      "  -0.5562824  -0.11577738  0.01810146 -0.10536947  0.07183728  0.05874278\n",
      "   0.43677098 -0.16668737  0.01021575  0.05963009 -0.03090432 -0.13102242\n",
      "   0.18614751  0.13063452  0.04894596  0.04302438  0.33930963  0.36994925\n",
      "  -0.01409349  0.01236203 -0.01782743  0.04562677  0.08322706 -0.09145668\n",
      "   0.03557287  0.05164042  0.02314351  0.08243123  0.12775126  0.06966085\n",
      "   0.12123352  0.36728483  0.48453709 -0.1516519   0.03316482 -0.0123687\n",
      "  -0.32789484  0.02922312 -0.29082173  0.09756328  0.16902158 -0.19181284\n",
      "  -0.19844265 -0.19888473  0.05569024  0.18603702 -0.48650596 -0.17591265]\n",
      " [-0.05923684  0.17109026 -0.27417892  0.20940925 -0.09679801 -0.03086549\n",
      "   0.21577458  0.02603678 -0.21074523  0.10994164 -0.14057852 -0.17929302\n",
      "   0.50960153  0.35670811  0.15765785 -0.30953771 -0.02460255  0.00141478\n",
      "  -0.42235729  0.04459151 -0.00066365 -0.12302727  0.05910711  0.36000073\n",
      "  -0.16383901  0.00103003 -0.04537963  0.20432259  0.0838007  -0.29587916\n",
      "  -0.33329341 -0.04485526  0.17247456  0.06051142  0.0607917   0.00739777\n",
      "   0.03604014 -0.04272507 -0.12794654 -0.06654415  0.20372914 -0.0452698\n",
      "  -0.05221559 -0.24980426 -0.16259404  0.36240637 -0.248623   -0.20868196\n",
      "   0.17052744 -0.0639673   0.30236527  0.13860765 -0.21335974 -0.15767188\n",
      "  -0.13449979  0.01312657  0.08489931  0.07782469  0.20839241  0.12423608]\n",
      " [ 0.52126527  0.00431558 -0.04126624 -0.01407296 -0.23717931 -0.03844649\n",
      "  -0.0527091  -0.07186732  0.09429116 -0.06973922  0.23242815 -0.03001141\n",
      "  -0.44699487 -0.17539349 -0.0539404   0.14393932  0.17861585  0.0553614\n",
      "   0.29811871  0.096072   -0.03454963  0.07438853  0.02926035  0.01443055\n",
      "   0.14962842  0.19110715  0.00730035  0.10000744  0.25713116  0.1883207\n",
      "  -0.05685302  0.06127354 -0.16830175  0.05580732 -0.0273376  -0.17194428\n",
      "   0.01185636  0.04293504 -0.02261488  0.1158688  -0.03024387  0.06946306\n",
      "  -0.00137617  0.450966    0.44522622  0.06551315  0.12970531  0.10527938\n",
      "  -0.30793431 -0.04398484 -0.18987116  0.02358238  0.23089474 -0.09777966\n",
      "  -0.07097006 -0.05942883 -0.08740332  0.00752881 -0.515751   -0.05762383]\n",
      " [-0.04210753  0.10662527 -0.14590675  0.15341273  0.13446163  0.13537502\n",
      "   0.06244805  0.02920817 -0.13305242  0.01420681 -0.0741226  -0.23321073\n",
      "   0.1585826   0.13477223  0.16703534 -0.10316048 -0.17088023  0.25320271\n",
      "  -0.1912756   0.14663655 -0.13677938 -0.09933849 -0.07058357  0.12772079\n",
      "  -0.07722453 -0.10585913 -0.12524217  0.10434319 -0.12731291 -0.11189484\n",
      "  -0.1641335   0.05329917  0.24107395  0.04047212  0.25343278  0.14262225\n",
      "   0.1121059  -0.04301693 -0.13084924 -0.22233085  0.18508171 -0.12822407\n",
      "  -0.13899244 -0.10254086 -0.08108122  0.24722444 -0.05801457 -0.03686158\n",
      "   0.1591347   0.03950378  0.18014695  0.05610652 -0.11840763 -0.06781659\n",
      "  -0.23353694  0.04542096 -0.06101601  0.04171649  0.03406196  0.12463706]\n",
      " [ 0.52126527  0.00431558 -0.04126624 -0.01407296 -0.23717931 -0.03844649\n",
      "  -0.0527091  -0.07186732  0.09429116 -0.06973922  0.23242815 -0.03001141\n",
      "  -0.44699487 -0.17539349 -0.0539404   0.14393932  0.17861585  0.0553614\n",
      "   0.29811871  0.096072   -0.03454963  0.07438853  0.02926035  0.01443055\n",
      "   0.14962842  0.19110715  0.00730035  0.10000744  0.25713116  0.1883207\n",
      "  -0.05685302  0.06127354 -0.16830175  0.05580732 -0.0273376  -0.17194428\n",
      "   0.01185636  0.04293504 -0.02261488  0.1158688  -0.03024387  0.06946306\n",
      "  -0.00137617  0.450966    0.44522622  0.06551315  0.12970531  0.10527938\n",
      "  -0.30793431 -0.04398484 -0.18987116  0.02358238  0.23089474 -0.09777966\n",
      "  -0.07097006 -0.05942883 -0.08740332  0.00752881 -0.515751   -0.05762383]\n",
      " [-0.14242433 -0.0089051   0.07817495 -0.15384376 -0.06506146 -0.17795667\n",
      "  -0.23387709 -0.14047004  0.11233536 -0.02264638  0.09093392  0.1597538\n",
      "  -0.08725035 -0.15575956  0.05513778  0.16622713  0.11899965 -0.06804163\n",
      "   0.11093573 -0.09161139  0.17237198  0.0812491   0.05272645 -0.07496778\n",
      "  -0.06211102 -0.16298562  0.16783485 -0.2199254   0.19979918 -0.01546613\n",
      "   0.08020207  0.01794105 -0.21001603 -0.08331943 -0.03110718  0.05122006\n",
      "  -0.22402953 -0.043454   -0.01652628  0.13605917 -0.0685344   0.06316947\n",
      "   0.05430363  0.04682172 -0.00092297 -0.06898506  0.15701498 -0.05505549\n",
      "  -0.16816854 -0.07305533 -0.06262335 -0.0830732   0.09045829  0.00927317\n",
      "   0.2660737  -0.1697754   0.17844182 -0.13580477 -0.01075571 -0.00432271]\n",
      " [ 0.0499203   0.15353441  0.06735977 -0.11949076 -0.07111828 -0.15325449\n",
      "  -0.08373739 -0.07260776 -0.01772292 -0.09584868 -0.01539029  0.12510233\n",
      "  -0.15994231 -0.11459792  0.07665401  0.06220789  0.04962455 -0.12552656\n",
      "   0.02562349 -0.07942298  0.01213293  0.00872709  0.11750251 -0.02055496\n",
      "   0.02988756  0.03029173  0.13568117 -0.01509359  0.14015722  0.0014078\n",
      "   0.1447043  -0.06888426  0.0259378  -0.06971557 -0.09214612  0.06444617\n",
      "  -0.01919829 -0.02839088  0.04149966  0.08505311 -0.04496767  0.00129396\n",
      "   0.05593843  0.03391234 -0.05734287 -0.16296226  0.08982368 -0.02706976\n",
      "   0.0330415   0.0582318   0.03947578 -0.06685234  0.2164683  -0.09727025\n",
      "   0.02684009 -0.1020259   0.04322496 -0.11049104  0.01496133  0.16172718]\n",
      " [-0.03115265 -0.14081979  0.18109424 -0.08109763  0.28308299 -0.17047989\n",
      "  -0.09285047 -0.12880081  0.22656523 -0.36422864  0.03860463  0.14446731\n",
      "   0.12780386 -0.20141611  0.05448997  0.29548383 -0.08744622 -0.05070418\n",
      "  -0.11236221 -0.09047116  0.39596131 -0.07867268  0.1163267  -0.07720935\n",
      "  -0.16353622 -0.09928042  0.17541647 -0.30031437  0.03765502  0.0528492\n",
      "   0.07216424 -0.19277751  0.06861299  0.02021854 -0.12028715 -0.07960646\n",
      "  -0.14801434 -0.1571079  -0.02466626 -0.13008493 -0.22513923  0.07426765\n",
      "   0.13582143 -0.23883568 -0.20463863 -0.24391741  0.08554661  0.06069454\n",
      "   0.16596681  0.07584017 -0.10866436 -0.22689953 -0.12006748  0.07048797\n",
      "   0.18578663 -0.06135613  0.25734591 -0.0589441   0.04836493  0.06590261]]\n"
     ]
    }
   ],
   "source": [
    "net              = LSTM_bidi()                                       # load trained LSTM model\n",
    "\n",
    "w_indices        = [net.voc.index(w) for w in words]                 # convert input sentence to word IDs\n",
    "Gx, Gx_rev       = net.backward(w_indices, target_class)             # perform gradient backpropagation\n",
    "R_words_SA       = (np.linalg.norm(Gx + Gx_rev, ord=2, axis=1))**2   # compute word-level Sensitivity Analysis relevances\n",
    "R_words_GI       = ((Gx + Gx_rev)*net.x).sum(axis=1)                 # compute word-level GradientxInput relevances\n",
    "\n",
    "scores           = net.s.copy()                                      # classification prediction scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction scores:        [ 2.73149687  2.7249559   0.80547211 -1.5359282  -4.6083298 ]\n",
      "\n",
      "SA/GI target class:       0\n",
      "\n",
      "SA relevances:\n",
      "\t\t\t    5.01\tneither\n",
      "\t\t\t    0.35\tfunny\n",
      "\t\t\t    0.73\tnor\n",
      "\t\t\t    0.92\tsuspenseful\n",
      "\t\t\t    1.66\tnor\n",
      "\t\t\t    0.13\tparticularly\n",
      "\t\t\t    0.66\twell-drawn\n",
      "\t\t\t    0.32\t.\n",
      "\n",
      "SA heatmap:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#ff0000\">neither</span> <span style=\"background-color:#ffeeee\">funny</span> <span style=\"background-color:#ffdada\">nor</span> <span style=\"background-color:#ffd0d0\">suspenseful</span> <span style=\"background-color:#ffaaaa\">nor</span> <span style=\"background-color:#fff8f8\">particularly</span> <span style=\"background-color:#ffdede\">well-drawn</span> <span style=\"background-color:#ffeeee\">.</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GI relevances:\n",
      "\t\t\t    0.03\tneither\n",
      "\t\t\t    0.06\tfunny\n",
      "\t\t\t   -0.11\tnor\n",
      "\t\t\t   -0.19\tsuspenseful\n",
      "\t\t\t   -0.19\tnor\n",
      "\t\t\t   -0.07\tparticularly\n",
      "\t\t\t   -0.06\twell-drawn\n",
      "\t\t\t    0.03\t.\n",
      "\n",
      "GI heatmap:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#ffdede\">neither</span> <span style=\"background-color:#ffb3b3\">funny</span> <span style=\"background-color:#6868ff\">nor</span> <span style=\"background-color:#0000ff\">suspenseful</span> <span style=\"background-color:#0000ff\">nor</span> <span style=\"background-color:#a2a2ff\">particularly</span> <span style=\"background-color:#acacff\">well-drawn</span> <span style=\"background-color:#ffdcdc\">.</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (\"prediction scores:       \",   scores)\n",
    "print (\"\\nSA/GI target class:      \", target_class)\n",
    "print (\"\\nSA relevances:\")\n",
    "for idx, w in enumerate(words):\n",
    "    print (\"\\t\\t\\t\" + \"{:8.2f}\".format(R_words_SA[idx]) + \"\\t\" + w)\n",
    "print (\"\\nSA heatmap:\")    \n",
    "display(HTML(html_heatmap(words, R_words_SA)))\n",
    "print (\"\\nGI relevances:\")\n",
    "for idx, w in enumerate(words):\n",
    "    print (\"\\t\\t\\t\" + \"{:8.2f}\".format(R_words_GI[idx]) + \"\\t\" + w)\n",
    "print (\"\\nGI heatmap:\")    \n",
    "display(HTML(html_heatmap(words, R_words_GI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
